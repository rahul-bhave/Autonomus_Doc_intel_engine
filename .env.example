# ==============================================================================
# Environment Variables â€” Autonomous Document Intel Engine
# ==============================================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control.
# ==============================================================================

# --- LLM: IBM Watsonx (Sprint 6) ---
# Required only when IBM Watsonx is configured as the LLM backend.
WATSONX_API_KEY=your_watsonx_api_key_here
WATSONX_PROJECT_ID=your_watsonx_project_id_here
WATSONX_URL=https://us-south.ml.cloud.ibm.com

# --- LLM: Ollama (Sprint 6) ---
# Default Ollama URL when running locally. Change if Ollama runs on a remote host.
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# --- Pipeline Configuration ---
# Confidence threshold below which the LLM fallback is triggered.
# Overrides the per-category threshold in the YAML when set.
# Leave blank to use per-category YAML thresholds (recommended).
# CONFIDENCE_THRESHOLD_OVERRIDE=0.60

# --- Storage Paths ---
# All paths should be absolute or relative to the project root.
DOC_INPUT_PATH=data/input
DOC_OUTPUT_PATH=data/output
AUDIT_LOG_PATH=logs/audit.jsonl
FEEDBACK_PATH=feedback
DB_PATH=data/documents.db

# --- Debug ---
# Set to 'true' to persist parsed Markdown to disk (data/output/<doc_id>.md).
# Leave 'false' in production (parsed Markdown is in-memory only per BRD Section 7.3).
DEBUG_PERSIST_MARKDOWN=false

# --- Logging ---
LOG_LEVEL=INFO

# --- Authentication (Sprint 7/8) ---
# Basic auth credentials for Chainlit and Gradio interfaces.
CHAINLIT_USERNAME=admin
CHAINLIT_PASSWORD=changeme
GRADIO_USERNAME=qe
GRADIO_PASSWORD=changeme
